<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LangChain Fundamentals :: LangChain AI</title>
    <link>http://localhost:1313/langchain_project_book/fundamentals/index.html</link>
    <description>The fundamental ideas and elements of LangChain, a framework for creating language-model-powered applications, are covered in this chapter. LangChain aims to develop data-aware and agentic applications that enable language models to communicate with their surroundings and establish connections with other data sources, rather than only calling out to a language model via an API.&#xA;At the heart of LangChain are two key components. The first one is the modular abstractions provided by LangChain, which are essential for working with language models. These components are designed to be easy to use, whether you use the rest of the LangChain framework or not.</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 28 Oct 2024 18:56:59 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/langchain_project_book/fundamentals/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LangChain Architecture</title>
      <link>http://localhost:1313/langchain_project_book/fundamentals/architecture/index.html</link>
      <pubDate>Thu, 24 Oct 2024 00:10:48 -0400</pubDate>
      <guid>http://localhost:1313/langchain_project_book/fundamentals/architecture/index.html</guid>
      <description>The architectural components of LangChain, illustrated in Figure 1.1, will be thoroughly explored and discussed in detail throughout the book.&#xA;package LangChain { package Agent_Tooling { agent Tools agent Toolkits } package Models_IO { agent Model agent Prompt agent Output_Parser } package Chain_and_Retrieval { agent Retriever agent Document_Loaders agent VectorStore agent TextSplitter agent Embedding_Model } } Chain_and_Retrieval -[hidden] Models_IO Models_IO -[hidden] Agent_Tooling Model -[hidden]- Prompt Prompt -[hidden]- Output_Parser Retriever -[hidden] Document_Loaders Document_Loaders -[hidden]- VectorStore VectorStore -[hidden] TextSplitter TextSplitter -[hidden]- Embedding_Model Tools -[hidden]- Toolkits Figure 1.1: LangChain Architecture</description>
    </item>
    <item>
      <title>Select a Right Language Model</title>
      <link>http://localhost:1313/langchain_project_book/fundamentals/select_a_right_lm/index.html</link>
      <pubDate>Mon, 28 Oct 2024 17:52:48 +0800</pubDate>
      <guid>http://localhost:1313/langchain_project_book/fundamentals/select_a_right_lm/index.html</guid>
      <description>When selecting a language model and an embedding model in LangChain technology, there are several things to consider:&#xA;Primary Task: Identify the core functions of the language model (LLM), which include tasks like text generation, summarization, translation, and answering queries. A valuable resource to explore these tasks is https://huggingface.co/models covering a wide range from Multimodal to Computer Vision (CV) and Natural Language Processing (NLP). Common examples in this context involve Summarization, Text Generation, and Question Answering within NLP.</description>
    </item>
    <item>
      <title>LLM Settings and Limits</title>
      <link>http://localhost:1313/langchain_project_book/fundamentals/llm_settings_n_limits/index.html</link>
      <pubDate>Mon, 28 Oct 2024 17:58:27 +0800</pubDate>
      <guid>http://localhost:1313/langchain_project_book/fundamentals/llm_settings_n_limits/index.html</guid>
      <description>LLM Settings When working with prompts, you can communicate directly or through an API with the LLM. A few parameters can be set to get different outcomes for your prompts.&#xA;temperature: In other words, results are more deterministic when the temperature is lower because the next most likely token is always selected. A higher temperature may cause more unpredictability, which promotes more varied or imaginative results. In essence, you are making the other potential tokens heavier. In order toTo encourage more factual and succinct responses, you might want to apply a lower temperature value for tasks like fact-based quality assurance. It could be useful to raise the temperature value for writing poems or other creative tasks. The impact of adjusting this value can vary significantly based on the settings of the pre-trained model. Hence, it is advisable to experiment with and fine-tune this parameter according to the specific models to align with your requirements.</description>
    </item>
    <item>
      <title>Thoughts on Prompt Engineering</title>
      <link>http://localhost:1313/langchain_project_book/fundamentals/thoughts_on_prompt/index.html</link>
      <pubDate>Mon, 28 Oct 2024 18:10:58 +0800</pubDate>
      <guid>http://localhost:1313/langchain_project_book/fundamentals/thoughts_on_prompt/index.html</guid>
      <description>The process of creating meaningful prompts or instructions for an AI system or language model is known as “prompt engineering”. The model’s responses and behaviors are greatly influenced by these cues. Prompts with a good design facilitate researchers and developers to modify the output of AI systems to accomplish desired results and enhance the model’s functionality.&#xA;folder INSTRUCTION { artifact &#34;&#34;&#34;&#34;Answer the question based on the context below.\nIf the question cannot be answer using the \ninformation provided answer with &#34;I don&#39;t know&#34;.&#34; } folder CONTEXT { artifact &#34;Italian cuisine has a rich and diverse history that spans centuries \nand has been influenced by numerous cultures. In the Roman Empire, food \nwas a significant part of social life. Romans loved feasting and trying \nnew dishes, and their banquets often featured complex, intricate \nflavors that required sophisticated preparation techniques. They \nembraced the flavors and ingredients of many of the lands they had \nconquered, such as spices from the Middle East, fish from the \nMediterranean, and cereals from North Africa. This fusion of diverse \ningredients made the Empire a hot spot for culinary innovation&#34; } folder QUESTIONS { artifact &#34;What is the history of Italian cuisine?&#34; } folder ANSWER { artifact &#34;&#34;&#34;&#34;&#34;&#34;&#34; } INSTRUCTION -[hidden]- CONTEXT CONTEXT -[hidden]- QUESTIONS QUESTIONS -[hidden] ANSWER Figure 1.3: Prompt Template</description>
    </item>
    <item>
      <title>Embeddings and VectorStore</title>
      <link>http://localhost:1313/langchain_project_book/fundamentals/embedding_n_vectorstore/index.html</link>
      <pubDate>Mon, 28 Oct 2024 18:17:09 +0800</pubDate>
      <guid>http://localhost:1313/langchain_project_book/fundamentals/embedding_n_vectorstore/index.html</guid>
      <description>In LangChain, a Python library designed to simplify the process of building Natural Language Processing (NLP) applications using LLMs, embeddings and VectorStore play a crucial role in enhancing the accuracy and efficiency of these applications.&#xA;Understanding Embeddings In the realm of LLMs, embeddings serve as numeric depictions of words, phrases, or sentences, encapsulating their semantic meaning and context. These embeddings facilitate text representation in a machine-learning-friendly format, supporting a range of NLP endeavors. Commonly pretrained on vast text datasets, embeddings such as Word2Vec, GloVe, and FastText capture semantic connections and resemblances among words. By converting words into vectors, these embeddings streamline tasks like text analysis and generation, empowering models to comprehend and handle language proficiently by leveraging contextual cues.</description>
    </item>
    <item>
      <title>Chains and Retriever</title>
      <link>http://localhost:1313/langchain_project_book/fundamentals/chains_n_retriever/index.html</link>
      <pubDate>Mon, 28 Oct 2024 18:49:37 +0800</pubDate>
      <guid>http://localhost:1313/langchain_project_book/fundamentals/chains_n_retriever/index.html</guid>
      <description>LangChain can easily orchestrate interactions with language models, chain together various components, and incorporate resources like databases and APIs. We will examine two fundamental ideas in LangChain in this chapter: Chain and Retriever.&#xA;Understanding Chains LangChain relies heavily on chains. The core of LangChain’s operation is these logical relationships among one or more LLMs. Depending on the requirements and LLMs involved, chains might be simple or complex. An LLM model, an output parser that is optional, and a PromptTemplate are all part of its organized configuration. The LLMChain in this configuration takes in a variety of input parameters. It converts these inputs into a logical prompt by using the PromptTemplate. The model is then fed this polished cue. Following receipt of the output, the LLMChain formats and further refines the result into its most useable form using the OutputParser, if one is supplied.</description>
    </item>
    <item>
      <title>Document and Debugging</title>
      <link>http://localhost:1313/langchain_project_book/fundamentals/document_n_debugging/index.html</link>
      <pubDate>Mon, 28 Oct 2024 18:54:03 +0800</pubDate>
      <guid>http://localhost:1313/langchain_project_book/fundamentals/document_n_debugging/index.html</guid>
      <description>Understanding LangChain’s API offers the following advantages:&#xA;Facilitating application development. Assisting in debugging by enabling verbose mode to provide more detailed traces. API Document in LangChain LangChain provides an API that enables developers to easily interact with LLM and other computational resources or knowledge sources. This makes it easier to build applications such as question answering systems, chatbots, and intelligent agents.&#xA;I advise you to often check out the latest LangChain API reference, where you may examine incredibly thorough API logic at https://api.python.langchain.com/en/latest/ .</description>
    </item>
    <item>
      <title>Summary</title>
      <link>http://localhost:1313/langchain_project_book/fundamentals/summary/index.html</link>
      <pubDate>Mon, 28 Oct 2024 18:56:59 +0800</pubDate>
      <guid>http://localhost:1313/langchain_project_book/fundamentals/summary/index.html</guid>
      <description>Throughout this chapter, we have acquired proficiency in the following key areas:&#xA;LangChain Architecture and Workflow: Grasping the structure and operational flow of LangChain for efficient application development. Models: Selecting appropriate language and embedding models for content embedding and generation. Prompt and Prompt Template: Introducing the use of prompts and templates to guide interactions with models, providing various examples to demonstrate their impact on the chain’s outcomes. Chain: Comprehending the sequential procedures within the system to uphold a coherent data operation flow and acknowledging the chain’s role in the comprehensive retrieval-augmented generation (RAG) process. For instance, retrieving relevant data from a retriever (vector store), combining it with a template, and forwarding it to an LLM for content generation. Debug and Verbose: Activating debugging and verbose modes to facilitate error identification and detailed logging for efficient troubleshooting. Enabling debugging and verbose modes for effective error detection and comprehensive logging to streamline issue resolution processes. By understanding the skills presented in the “LangChain Fundamentals” chapter, readers will be well-prepared to engage in application development using LangChain and its associated technologies.</description>
    </item>
  </channel>
</rss>