<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LangChain Fundamentals :: LangChain AI</title>
    <link>http://localhost:1313/j3ffyang/langchain_project_book/fundamentals/index.html</link>
    <description>The fundamental ideas and elements of LangChain, a framework for creating language-model-powered applications, are covered in this chapter. LangChain aims to develop data-aware and agentic applications that enable language models to communicate with their surroundings and establish connections with other data sources, rather than only calling out to a language model via an API.&#xA;At the heart of LangChain are two key components. The first one is the modular abstractions provided by LangChain, which are essential for working with language models. These components are designed to be easy to use, whether you use the rest of the LangChain framework or not.</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 24 Oct 2024 00:10:48 -0400</lastBuildDate>
    <atom:link href="http://localhost:1313/j3ffyang/langchain_project_book/fundamentals/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LangChain Architecture</title>
      <link>http://localhost:1313/j3ffyang/langchain_project_book/fundamentals/architecture/index.html</link>
      <pubDate>Thu, 24 Oct 2024 00:10:48 -0400</pubDate>
      <guid>http://localhost:1313/j3ffyang/langchain_project_book/fundamentals/architecture/index.html</guid>
      <description>The architectural components of LangChain, illustrated in Figure 1.1, will be thoroughly explored and discussed in detail throughout the book.&#xA;package LangChain { package Agent_Tooling { agent Tools agent Toolkits } package Models_IO { agent Model agent Prompt agent Output_Parser } package Chain_and_Retrieval { agent Retriever agent Document_Loaders agent VectorStore agent TextSplitter agent Embedding_Model } } Chain_and_Retrieval -[hidden] Models_IO Models_IO -[hidden] Agent_Tooling Model -[hidden]- Prompt Prompt -[hidden]- Output_Parser Retriever -[hidden] Document_Loaders Document_Loaders -[hidden]- VectorStore VectorStore -[hidden] TextSplitter Document_Loaders -[hidden]- VectorStore TextSplitter -[hidden]- Embedding_Model Tools -[hidden]- Toolkits Model: also known as LLM model serve as the core elements of LangChain. They essentially act as wrappers for these models, enabling the utilization of their specific functionalities and capabilities. Chain: Chain enables us to integrate multiple components to address a specific task. It streamlines the process of implementing complex applications by enhancing modularity, making debugging and maintenance more straightforward. Document loaders: Document Loaders play a role in loading documents into the LangChain system, managing a range of document types like PDFs, and transforming them into a compatible format for LangChain processing. This procedure encompasses multiple stages, including data ingestion, context comprehension, and refinement. Prompt: Prompts serve as inputs for LLMs to generate specific responses. Crafting effective prompts is vital for obtaining valuable outputs from LLMs. Prompt engineering aims to create prompts that yield precise, relevant, and beneficial responses from LLMs. For instance, the prompt plays an amazing role in the output when examining the prompt in OpenAIâ€™s Sora, which creates stunning and visually striking videos. VectorStore: It brings functions for the effective storage and retrieval of vector embeddings. And it operates as a repository for vectors containing supplementary data, streamlining the processes of storage, search, and point management. Output Parsers: The output_parser converts the output of an LLM into a more appropriate format, especially beneficial when generating structured data using LLMs. Agents: LLMs can communicate with their surroundings through agents. For instance, carrying out a particular task via an external API, or grabbing extra data from outside website. LangChain utilizes a sequential pipeline method to construct tailored applications for LLM. This structured approach integrates diverse services, data inputs, and formatting processes, ensuring accurate processing and consistent output. Modules in LangChain follow a step-by-step process with single inputs and outputs, facilitating smooth data flow. This mechanism simplifies development and enhances LLM utilization. By streamlining workflows, LangChain optimizes AI application development, executing steps in a specific order to real-world processes for managed outcomes. ### LangChain Workflow</description>
    </item>
  </channel>
</rss>