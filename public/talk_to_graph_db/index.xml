<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Talk to Your GraphDB :: LangChain AI</title>
    <link>http://localhost:1313/langchain_project_book/talk_to_graph_db/index.html</link>
    <description>In summer of 2024, I received a request from our Sales, who manages the engagement with public service. The customer has multiple diementions of dataset and what they want is like&#xA;Link the different diementaional dataset together Gives them a better graphical visualization of data relationships As they don’t have much technical skills, they can’t handle SQL script and wish to “talk” to the database in their native language. Then the application responds the printable data-sheet What I can think is to enable three things and combine them together</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 Jan 2025 22:04:12 -0500</lastBuildDate>
    <atom:link href="http://localhost:1313/langchain_project_book/talk_to_graph_db/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Architecture</title>
      <link>http://localhost:1313/langchain_project_book/talk_to_graph_db/arch/index.html</link>
      <pubDate>Fri, 03 Jan 2025 22:04:12 -0500</pubDate>
      <guid>http://localhost:1313/langchain_project_book/talk_to_graph_db/arch/index.html</guid>
      <description>Architecture actor User node LLM database Neo4j User -&gt; LLM: Ask a question LLM -&gt; Neo4j: Query the graph database Neo4j -&gt; LLM: Return the result LLM -&gt; User: Answer the question Figure 7.1: The architecture of the application</description>
    </item>
    <item>
      <title>Using Neo4j as Graph Database</title>
      <link>http://localhost:1313/langchain_project_book/talk_to_graph_db/using_neo4j/index.html</link>
      <pubDate>Fri, 03 Jan 2025 22:04:12 -0500</pubDate>
      <guid>http://localhost:1313/langchain_project_book/talk_to_graph_db/using_neo4j/index.html</guid>
      <description>Using neo4j as Graph Database Installing neo4j with Docker We would need to install neo4j with docker and persist the data to the local disk.&#xA;docker run --restart always --name=neo4j \ --publish=7474:7474 --publish=7687:7687 \ --env NEO4J_AUTH=neo4j/neo4j_password \ --volume /home/USER/neo4j_storage/data:/data \ --volume /home/USER/neo4j_storage/logs:/logs \ --volume /home/USER/neo4j_storage/import:/import \ neo4j:latest Note: we’re going to import the dataset into the database from CSV files, which would be stored in the /home/USER/neo4j_storage/import directory. Therefore, we need to create this directory before running the container. And copy the CSV files into this directory.</description>
    </item>
    <item>
      <title>Configuring LLM</title>
      <link>http://localhost:1313/langchain_project_book/talk_to_graph_db/config_llm/index.html</link>
      <pubDate>Fri, 03 Jan 2025 22:04:12 -0500</pubDate>
      <guid>http://localhost:1313/langchain_project_book/talk_to_graph_db/config_llm/index.html</guid>
      <description>Configuring LLM I recommend to either use ollama or directly connect to HuggingFace’s LLM model.&#xA;Using ollama Please refer to Chapter 4 - Document Summarization - Software Environment for more details.&#xA;Using HuggingFace’s LLM model Before using HuggingFace’s LLM model, you need to get the API token from HuggingFace.&#xA;import os HUGGINGFACEHUB_API_TOKEN = os.getenv(&#34;HUGGINGFACEHUB_API_TOKEN&#34;) from langchain_huggingface import HuggingFaceEndpoint repo_id = &#34;mistralai/Mistral-7B-Instruct-v0.2&#34; llm = HuggingFaceEndpoint( repo_id = repo_id, temperature = 0.5, huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN, max_new_tokens = 250, )</description>
    </item>
    <item>
      <title>Configuring Neo4j with LangChain</title>
      <link>http://localhost:1313/langchain_project_book/talk_to_graph_db/config_neo4j_lc/index.html</link>
      <pubDate>Fri, 03 Jan 2025 22:04:12 -0500</pubDate>
      <guid>http://localhost:1313/langchain_project_book/talk_to_graph_db/config_neo4j_lc/index.html</guid>
      <description>Configuring neo4j with langchain To communicate with a Neo4j graph database through a Large Language Model (LLM), you can leverage integration frameworks such as LangChain. Here’s how you can set up this interaction:&#xA;Integrate Neo4j with LangChain LangChain provides a robust framework for integrating LLMs with various data sources, including Neo4j. You can install the necessary packages using pip:&#xA;pip install langchain langchain-community langchain-neo4j neo This installation will allow you to utilize Langchain’s capabilities to interact with your Neo4j database.</description>
    </item>
    <item>
      <title>Summary</title>
      <link>http://localhost:1313/langchain_project_book/talk_to_graph_db/summary/index.html</link>
      <pubDate>Fri, 03 Jan 2025 22:04:12 -0500</pubDate>
      <guid>http://localhost:1313/langchain_project_book/talk_to_graph_db/summary/index.html</guid>
      <description>Summary Every component is 100% open source ollama and neo4j are running in docker, which is easy to deploy and manage Everything is running in local, which is easy to debug and test and secured</description>
    </item>
  </channel>
</rss>